[default]
#number of rnn layers
num_layers = 2
#number of units in each layer
num_units = 128
#the dropout rate between the layers
dropout = 0.5
#the attention mechanism that should be used, one of vanilla, location_aware,
#monotonic or windowed
attention = vanilla
#the probability function that should be used for the alignments, one of
#softmax or sigmoid
probability_fn = softmax
#the probability that the network will sample from the output during training
sample_prob = 0.1
